{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9263d84f",
   "metadata": {},
   "source": [
    "#### step1: environment setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec40968a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n",
      "/Users/xueqian.pan/.certs/netskope_openai.pem\n",
      "/Users/xueqian.pan/.certs/netskope_openai.pem\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from typing import List, Dict, Optional\n",
    "import dspy\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY']\n",
    "os.environ[\"SSL_CERT_FILE\"] = os.path.expanduser(\"~/.certs/netskope_openai.pem\")\n",
    "os.environ[\"REQUESTS_CA_BUNDLE\"] = os.path.expanduser(\"~/.certs/netskope_openai.pem\")\n",
    "print(os.environ['OPENAI_API_KEY'])\n",
    "print(os.environ[\"SSL_CERT_FILE\"])\n",
    "print(os.environ[\"REQUESTS_CA_BUNDLE\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4981304b",
   "metadata": {},
   "source": [
    "#### step2: load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7599d503",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "def load_rows_from_dataset(dataset_path: str) -> list[dict]:\n",
    "    # dataset_path = base_dir / f\"{dataset_name}.json\"\n",
    "    dataset_name = dataset_path.split(\"/\")[-1].split(\".\")[0]\n",
    "    with Path(dataset_path).open(\"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    rows: list[dict] = []\n",
    "    for convo in data.get(\"conversations\", []):\n",
    "        messages = convo.get(\"conversation\", [])\n",
    "        user_message = next((m for m in messages if m.get(\"role\") == \"user\"), None)\n",
    "        if user_message is None:\n",
    "            continue\n",
    "        target_tool_value = user_message.get(\"target_tool\")\n",
    "        if isinstance(target_tool_value, list):\n",
    "            target_tool_str = \",\".join(target_tool_value)\n",
    "        else:\n",
    "            target_tool_str = target_tool_value\n",
    "        target_handoff_str = user_message.get(\"target_handoff\")\n",
    "        \n",
    "        rows.append(\n",
    "            {\n",
    "                \"id\": convo.get(\"id\"),\n",
    "                \"content\": user_message.get(\"content\", \"\"),\n",
    "                \"target_tool\": target_tool_str,\n",
    "                \"target_handoff\": target_handoff_str,\n",
    "                \"dataset_name\": dataset_name,\n",
    "            }\n",
    "        )\n",
    "    return rows\n",
    "base_dir = \"/Users/xueqian.pan/Documents/code/project/shopping/ninjaeval_mlflow/ninjaeval_mlflow/dataset\"\n",
    "all_path = glob(base_dir+ \"/Handoff*.json\")\n",
    "all_path = [i for i in all_path if \"Handoff.json\" not in i and \"HandoffAll.json\" not in i]\n",
    "all_rows = []\n",
    "for name in all_path:\n",
    "    all_rows.extend(load_rows_from_dataset(name))\n",
    "df = pd.DataFrame(all_rows, columns=[\"id\", \"content\", \"target_tool\",'target_handoff','dataset_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcadf908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>target_tool</th>\n",
       "      <th>target_handoff</th>\n",
       "      <th>dataset_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ã‚½ãƒ‹ãƒ¼ã®ãƒ¯ã‚¤ãƒ¤ãƒ¬ã‚¹ãƒ˜ãƒƒãƒ‰ãƒ›ãƒ³ã‚’æ¢ã—ã¦ã„ã¾ã™</td>\n",
       "      <td>None</td>\n",
       "      <td>transfer_to_shopping_agent</td>\n",
       "      <td>HandoffShopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ã‚­ãƒ£ãƒãƒ³ã®ãƒ‡ã‚¸ã‚¿ãƒ«ã‚«ãƒ¡ãƒ©ã‚’è²·ã„ãŸã„</td>\n",
       "      <td>None</td>\n",
       "      <td>transfer_to_shopping_agent</td>\n",
       "      <td>HandoffShopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Nintendo Switchã®æœ€æ–°ã‚²ãƒ¼ãƒ ã‚’è¦‹ã›ã¦</td>\n",
       "      <td>None</td>\n",
       "      <td>transfer_to_shopping_agent</td>\n",
       "      <td>HandoffShopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>æ±èŠã®ãƒãƒ¼ãƒˆãƒ‘ã‚½ã‚³ãƒ³ã‚’è¦‹ãŸã„</td>\n",
       "      <td>None</td>\n",
       "      <td>transfer_to_shopping_agent</td>\n",
       "      <td>HandoffShopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ã‚¢ãƒƒãƒ—ãƒ«ã‚¦ã‚©ãƒƒãƒã‚’è³¼å…¥ã—ãŸã„</td>\n",
       "      <td>None</td>\n",
       "      <td>transfer_to_shopping_agent</td>\n",
       "      <td>HandoffShopping</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                    content target_tool              target_handoff  \\\n",
       "0   0      ã‚½ãƒ‹ãƒ¼ã®ãƒ¯ã‚¤ãƒ¤ãƒ¬ã‚¹ãƒ˜ãƒƒãƒ‰ãƒ›ãƒ³ã‚’æ¢ã—ã¦ã„ã¾ã™        None  transfer_to_shopping_agent   \n",
       "1   1          ã‚­ãƒ£ãƒãƒ³ã®ãƒ‡ã‚¸ã‚¿ãƒ«ã‚«ãƒ¡ãƒ©ã‚’è²·ã„ãŸã„        None  transfer_to_shopping_agent   \n",
       "2   2  Nintendo Switchã®æœ€æ–°ã‚²ãƒ¼ãƒ ã‚’è¦‹ã›ã¦        None  transfer_to_shopping_agent   \n",
       "3   3             æ±èŠã®ãƒãƒ¼ãƒˆãƒ‘ã‚½ã‚³ãƒ³ã‚’è¦‹ãŸã„        None  transfer_to_shopping_agent   \n",
       "4   4             ã‚¢ãƒƒãƒ—ãƒ«ã‚¦ã‚©ãƒƒãƒã‚’è³¼å…¥ã—ãŸã„        None  transfer_to_shopping_agent   \n",
       "\n",
       "      dataset_name  \n",
       "0  HandoffShopping  \n",
       "1  HandoffShopping  \n",
       "2  HandoffShopping  \n",
       "3  HandoffShopping  \n",
       "4  HandoffShopping  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ad62ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target_handoff               dataset_name      \n",
       "transfer_to_web_search       HandoffAiwebsearch    102\n",
       "                             HandoffWeather         61\n",
       "transfer_to_music_and_video  HandoffVideosearch     55\n",
       "                             HandoffMusicsearch     50\n",
       "transfer_to_shopping_agent   HandoffShopping        48\n",
       "transfer_to_image_agent      HandoffImagesearch     30\n",
       "transfer_to_travel_agent     HandoffHotelsearch     30\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['target_handoff','dataset_name']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee2d89aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94, 94, 188)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "target_col = \"target_handoff\"\n",
    "input_col = \"content\"\n",
    "df2 = df.dropna(subset=[input_col, target_col]).copy()\n",
    "df2[input_col] = df2[input_col].astype(str).str.strip()\n",
    "df2[target_col] = df2[target_col].astype(str).str.strip()\n",
    "df2 = df2[(df2[input_col] != \"\") & (df2[target_col] != \"\")]\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    df2, test_size=0.5, random_state=42, stratify=df2[target_col]\n",
    ")\n",
    "train_df, val_df = train_test_split(\n",
    "    train_df, test_size=0.5, random_state=42, stratify=train_df[target_col]\n",
    ")\n",
    "\n",
    "def to_examples(d):\n",
    "    return [\n",
    "        dspy.Example(message=r[input_col], answer=r[target_col]).with_inputs(\"message\")\n",
    "        for _, r in d.iterrows()\n",
    "    ]\n",
    "\n",
    "train_set = to_examples(train_df)\n",
    "val_set = to_examples(val_df)\n",
    "test_set = to_examples(test_df)\n",
    "\n",
    "len(train_set), len(val_set), len(test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b0cea31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: target_handoff\n",
      "transfer_to_web_search         41\n",
      "transfer_to_music_and_video    26\n",
      "transfer_to_shopping_agent     12\n",
      "transfer_to_travel_agent        8\n",
      "transfer_to_image_agent         7\n",
      "Name: count, dtype: int64\n",
      "val: target_handoff\n",
      "transfer_to_web_search         41\n",
      "transfer_to_music_and_video    26\n",
      "transfer_to_shopping_agent     12\n",
      "transfer_to_image_agent         8\n",
      "transfer_to_travel_agent        7\n",
      "Name: count, dtype: int64\n",
      "test: target_handoff\n",
      "transfer_to_web_search         81\n",
      "transfer_to_music_and_video    53\n",
      "transfer_to_shopping_agent     24\n",
      "transfer_to_image_agent        15\n",
      "transfer_to_travel_agent       15\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\",train_df['target_handoff'].value_counts())\n",
    "print(\"val:\",val_df['target_handoff'].value_counts())\n",
    "print(\"test:\",test_df['target_handoff'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ccb509",
   "metadata": {},
   "source": [
    "#### step3: GEPA setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8313bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Literal\n",
    "import dspy\n",
    "config_set = {\n",
    "    \"base_model\": \"openai/gpt-4.1\", # inference model to generate the answer for a provided query\n",
    "    \"base_temperature\": 1,\n",
    "    \"base_max_tokens\": 5000, # max tokens for the inference model\n",
    "    \"base_top_p\": 1,\n",
    "    \"base_seed\": 42,\n",
    "    \"reflection_model\": \"openai/gpt-4.1\", # reflection model to collect feedback and adjust the prompt\n",
    "    \"classification\":False,\n",
    "    \"classes\":df['target_handoff'].dropna().unique().tolist(),\n",
    "    \"reflection_minibatch_size\":30, # the number of examples to collect feedback for each iteration\n",
    "    \"opt_mode\":'light'#light,medium,heavy, less iteration step when light\n",
    "    \"prompt_max_tokens\":500, # max tokens for the reflection model(max prompt length)\n",
    "}\n",
    "\n",
    "# max_metric_calls\n",
    "# light mean ~1k metric calls: train_set + x * (mini_batch + validation)\n",
    "# medium mean 3k~5k metric calls: train_set + x * (mini_batch + validation) \n",
    "# heavy mean 10k+: train_set + x * (mini_batch + validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbeaa02",
   "metadata": {},
   "source": [
    "<!-- ## dspy.Signature å­—æ®µè¯´æ˜\n",
    "\n",
    "### å½“å‰ä»£ç ï¼ˆåˆ†ç±»ä»»åŠ¡ï¼‰ï¼š\n",
    "- **`message`**: `dspy.InputField()` - è¾“å…¥å­—æ®µï¼Œè¡¨ç¤ºç”¨æˆ·çš„è¾“å…¥æ¶ˆæ¯\n",
    "- **`agent`**: `dspy.OutputField()` - è¾“å‡ºå­—æ®µï¼Œè¡¨ç¤ºæ¨¡å‹è¾“å‡ºçš„è·¯ç”±ç›®æ ‡ï¼ˆåˆ†ç±»ç»“æœï¼‰\n",
    "\n",
    "### å¦‚æœä¸æ˜¯åˆ†ç±»ä»»åŠ¡ï¼Œ`agent` å­—æ®µå¯ä»¥è¿™æ ·å®šä¹‰ï¼š\n",
    "\n",
    "1. **è‡ªç”±æ–‡æœ¬ç”Ÿæˆä»»åŠ¡**ï¼š\n",
    "   ```python\n",
    "   class TextGeneration(dspy.Signature):\n",
    "       message: str = dspy.InputField()\n",
    "       agent: str = dspy.OutputField()  # ä»»æ„å­—ç¬¦ä¸²\n",
    "   ```\n",
    "\n",
    "2. **æ•°å€¼å›å½’ä»»åŠ¡**ï¼š\n",
    "   ```python\n",
    "   class RegressionTask(dspy.Signature):\n",
    "       message: str = dspy.InputField()\n",
    "       agent: float = dspy.OutputField()  # æˆ– int\n",
    "   ```\n",
    "\n",
    "3. **å¤šæ ‡ç­¾åˆ†ç±»**ï¼š\n",
    "   ```python\n",
    "   class MultiLabel(dspy.Signature):\n",
    "       message: str = dspy.InputField()\n",
    "       agent: List[str] = dspy.OutputField()  # å¤šä¸ªç±»åˆ«\n",
    "   ```\n",
    "\n",
    "4. **ç»“æ„åŒ–è¾“å‡º**ï¼š\n",
    "   ```python\n",
    "   class StructuredOutput(dspy.Signature):\n",
    "       message: str = dspy.InputField()\n",
    "       agent: Dict[str, Any] = dspy.OutputField()  # JSON å¯¹è±¡\n",
    "   ```\n",
    "\n",
    "**æ³¨æ„**ï¼šå­—æ®µå `agent` åªæ˜¯å˜é‡åï¼Œå¯ä»¥æ ¹æ®ä½ çš„ä»»åŠ¡è¯­ä¹‰ä¿®æ”¹ï¼ˆå¦‚ `answer`, `result`, `output` ç­‰ï¼‰ -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ecb559",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  evaluate model\n",
    "lm = dspy.LM(config_set['base_model'], temperature=config_set['base_temperature']\\\n",
    "    ,top_p=config_set['base_top_p'],seed=config_set['base_seed']\n",
    "    ,max_tokens=config_set['base_max_tokens'], api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "# using Literal to define the agent\n",
    "if config_set['classification']:\n",
    "    literal_agent = eval(f\"Literal[{', '.join(repr(opt) for opt in config_set['classes'])}]\", {'Literal': Literal})\n",
    "    class agentrouting(dspy.Signature):\n",
    "        \"\"\"\n",
    "        Read the provided message and find the most suitable agent.\n",
    "        \"\"\"\n",
    "        message: str = dspy.InputField()\n",
    "        agent: literal_agent = dspy.OutputField()\n",
    "else:\n",
    "    agentrouting_docstring = f\"\"\"Read the provided message and find the most suitable agent.\n",
    "    Available agents:{', '.join(config_set['classes'])} \n",
    "    You must select one of the agents listed above.\"\"\"\n",
    "    class agentrouting(dspy.Signature):\n",
    "        __doc__ = agentrouting_docstring\n",
    "        message: str = dspy.InputField() \n",
    "        agent: str = dspy.OutputField() \n",
    "class AgentAnalyzerMM(dspy.Module):\n",
    "    \"\"\"\n",
    "    Agent routing module using dspy with reasoning support. \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.routingmodel = dspy.ChainOfThought(\n",
    "            agentrouting, \n",
    "            rationale_field=dspy.OutputField(desc=\"explain why choose this agent\"), # if reasoning is not necessary, you can remove this field\n",
    "            rationale_field_type=str\n",
    "        )\n",
    "    \n",
    "    def forward(self, message):\n",
    "        \"\"\"\n",
    "        Forward pass: inference process\n",
    "        \n",
    "        Args:\n",
    "            message: query\n",
    "            \n",
    "        Returns:\n",
    "            dspy.Prediction: includes the agent field and reasoning (inference process)\n",
    "        \"\"\"\n",
    "        result = self.routingmodel(message=message)\n",
    "        prediction_dict = {\n",
    "            'agent': result.agent\n",
    "        }\n",
    "        \n",
    "        if hasattr(result, 'reasoning'):\n",
    "            prediction_dict['reasoning'] = result.reasoning\n",
    "        elif hasattr(result, 'rationale'):\n",
    "            prediction_dict['reasoning'] = result.rationale\n",
    "        \n",
    "        return dspy.Prediction(**prediction_dict)\n",
    "\n",
    "program = AgentAnalyzerMM()\n",
    "\n",
    "def score_agent(gold_agent, pred_agent):\n",
    "    \"\"\"\n",
    "    Compute score for the agent module.\n",
    "    \"\"\"\n",
    "    score = 1.0 if gold_agent == pred_agent else 0.0\n",
    "    return score\n",
    "\n",
    "\n",
    "def metric(example, pred, trace=None, pred_name=None, pred_trace=None):\n",
    "    \"\"\"\n",
    "    Metric function evaluating both correctness and prompt length.\n",
    "    \n",
    "    Evaluates two aspects:\n",
    "    1. Output match: Whether predicted agent matches gold standard  \n",
    "    Returns:\n",
    "        dspy.Prediction with combined score and feedback\n",
    "    \"\"\"\n",
    "    try:\n",
    "        predicted = getattr(pred, 'agent', getattr(pred, 'answer', str(pred)))\n",
    "        correct = predicted.strip().lower() == example.answer.strip().lower()\n",
    "        match_score = 1.0 if correct else 0.0\n",
    "        return dspy.Prediction(\n",
    "            score=match_score,\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        return dspy.Prediction(score=0.0, feedback=f\"error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb7f622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_example = test_set[0]\n",
    "# test_message = test_example.message\n",
    "# expected_answer = test_example.answer\n",
    "\n",
    "# print(f\"\\nğŸ“ message: {test_message}\")\n",
    "# print(f\"âœ… correct answer: {expected_answer}\")\n",
    "# result = program(test_message)\n",
    "# result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6cfc998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/188 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 177.00 / 188 (94.1%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 188/188 [01:13<00:00,  2.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/03 17:06:12 INFO dspy.evaluate.evaluate: Average Metric: 177.0 / 188 (94.1%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>answer</th>\n",
       "      <th>agent</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>çœ ã‚Œãªã„å¤œã«è´ãéŸ³æ¥½ã‚’æ¢ã—ã¦ã‚‹</td>\n",
       "      <td>transfer_to_music_and_video</td>\n",
       "      <td>transfer_to_music_and_video</td>\n",
       "      <td>ã“ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯ã€Œçœ ã‚Œãªã„å¤œã«è´ãéŸ³æ¥½ã€ã‚’æ¢ã—ã¦ã„ã‚‹ã¨ã„ã†å†…å®¹ãªã®ã§ã€éŸ³æ¥½ã«é–¢é€£ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒæœ€é©ã§ã™ã€‚æ„å›³ã•ã‚ŒãŸã‚¿ã‚¹ã‚¯ã¯éŸ³æ¥½ã®...</td>\n",
       "      <td>âœ”ï¸ [Prediction(\\n    score=1.0\\n)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>å¯¾ç§°æ€§ã®ç¾ã—ã„ç”»åƒã‚’è¦‹ãŸã„ã§ã™ã€‚</td>\n",
       "      <td>transfer_to_image_agent</td>\n",
       "      <td>transfer_to_image_agent</td>\n",
       "      <td>ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã€Œå¯¾ç§°æ€§ã®ç¾ã—ã„ç”»åƒã‚’è¦‹ãŸã„ã€ã¨è¿°ã¹ã¦ãŠã‚Šã€ç¾ã—ã„å¯¾ç§°æ€§ã«é–¢ã™ã‚‹ç”»åƒã‚’æ±‚ã‚ã¦ã„ã¾ã™ã€‚ã“ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¯ç”»åƒã®ç”Ÿæˆã‚„æ¤œç´¢ã‚’è¡Œã†...</td>\n",
       "      <td>âœ”ï¸ [Prediction(\\n    score=1.0\\n)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ã®é…é€çŠ¶æ³</td>\n",
       "      <td>transfer_to_web_search</td>\n",
       "      <td>transfer_to_shopping_agent</td>\n",
       "      <td>ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ã«é–¢é€£ã™ã‚‹é…é€çŠ¶æ³ã«ã¤ã„ã¦è³ªå•ã—ã¦ã„ã‚‹ãŸã‚ã€ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ã«ç‰¹åŒ–ã—ãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒæœ€é©ã§ã™ã€‚</td>\n",
       "      <td>âœ”ï¸ [Prediction(\\n    score=0.0\\n)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ä»Šæ—¥ã®æœè£…ã®ãŠã™ã™ã‚ã¯ï¼Ÿ</td>\n",
       "      <td>transfer_to_web_search</td>\n",
       "      <td>transfer_to_web_search</td>\n",
       "      <td>ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã€Œä»Šæ—¥ã®æœè£…ã®ãŠã™ã™ã‚ã¯ï¼Ÿã€ã¨å°‹ã­ã¦ãŠã‚Šã€ã“ã‚Œã¯æ°—è±¡æƒ…å ±ã‚„ãƒˆãƒ¬ãƒ³ãƒ‰æƒ…å ±ã«åŸºã¥ã„ãŸææ¡ˆãŒæ±‚ã‚ã‚‰ã‚Œã‚‹è³ªå•ã§ã™ã€‚ãã®ãŸã‚ã€ã‚¤ãƒ³ã‚¿...</td>\n",
       "      <td>âœ”ï¸ [Prediction(\\n    score=1.0\\n)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ä»Šæ—¥ç™ºç”Ÿã—ãŸåœ°éœ‡æƒ…å ±ã‚’æ•™ãˆã¦</td>\n",
       "      <td>transfer_to_web_search</td>\n",
       "      <td>transfer_to_web_search</td>\n",
       "      <td>ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ä»Šæ—¥ç™ºç”Ÿã—ãŸåœ°éœ‡æƒ…å ±ã‚’æ±‚ã‚ã¦ã„ã¾ã™ã€‚ã“ã‚Œã¯æœ€æ–°ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚„å¤©æ°—ã€ç½å®³ã«é–¢ã™ã‚‹æƒ…å ±ã‚’èª¿ã¹ã‚‹å¿…è¦ãŒã‚ã‚‹ãŸã‚ã€ã‚¦ã‚§ãƒ–æ¤œç´¢ãŒæœ€é©ã§ã™ã€‚</td>\n",
       "      <td>âœ”ï¸ [Prediction(\\n    score=1.0\\n)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>æœ€æ–°ã®iPhoneã®ç™ºå£²æ—¥ã¯ã„ã¤ã§ã™ã‹ï¼Ÿ</td>\n",
       "      <td>transfer_to_web_search</td>\n",
       "      <td>transfer_to_web_search</td>\n",
       "      <td>ã“ã®è³ªå•ã¯æœ€æ–°ã®iPhoneã®ç™ºå£²æ—¥ã¨ã„ã†ã€æœ€æ–°ã®ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚„å…·ä½“çš„ãªäº‹å®Ÿæƒ…å ±ã‚’æ±‚ã‚ã¦ã„ã‚‹ã‚‚ã®ã§ã‚ã‚Šã€ã‚¦ã‚§ãƒ–æ¤œç´¢ãŒæœ€é©ã§ã™ã€‚</td>\n",
       "      <td>âœ”ï¸ [Prediction(\\n    score=1.0\\n)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>è»Šã®ãƒ¬ãƒ“ãƒ¥ãƒ¼æ˜ åƒã‚’æ¢ã—ã¦ãã ã•ã„ã€‚</td>\n",
       "      <td>transfer_to_music_and_video</td>\n",
       "      <td>transfer_to_web_search</td>\n",
       "      <td>ã€Œè»Šã®ãƒ¬ãƒ“ãƒ¥ãƒ¼æ˜ åƒã‚’æ¢ã—ã¦ãã ã•ã„ã€ã¨ã„ã†ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¯ã€è»Šã«é–¢ã™ã‚‹ãƒ¬ãƒ“ãƒ¥ãƒ¼å‹•ç”»ã‚’æ¤œç´¢ã—ã¦æ¬²ã—ã„ã¨ã„ã†æ„å‘³ã§ã™ã€‚å‹•ç”»ã‚’èª¿ã¹ã‚‹ãŸã‚ã«ã¯ã‚¦...</td>\n",
       "      <td>âœ”ï¸ [Prediction(\\n    score=0.0\\n)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>ä»Šé€±æœ«ã€å±‹å¤–ã‚¤ãƒ™ãƒ³ãƒˆã¯é–‹å‚¬ã§ãã¾ã™ã‹ï¼Ÿ</td>\n",
       "      <td>transfer_to_web_search</td>\n",
       "      <td>transfer_to_web_search</td>\n",
       "      <td>ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ä»Šé€±æœ«ã®å±‹å¤–ã‚¤ãƒ™ãƒ³ãƒˆã®é–‹å‚¬å¯å¦ã«ã¤ã„ã¦å°‹ã­ã¦ãŠã‚Šã€ã“ã‚Œã¯å¤©å€™æƒ…å ±ã«é–¢é€£ã™ã‚‹è³ªå•ã§ã™ã€‚æœ€æ–°ã®å¤©æ°—äºˆå ±ã‚’èª¿ã¹ã‚‹å¿…è¦ãŒã‚ã‚‹ãŸã‚ã€...</td>\n",
       "      <td>âœ”ï¸ [Prediction(\\n    score=1.0\\n)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>What is the most popular frozen food sold on Rakuten</td>\n",
       "      <td>transfer_to_shopping_agent</td>\n",
       "      <td>transfer_to_shopping_agent</td>\n",
       "      <td>The user is asking about the most popular frozen food sold on Raku...</td>\n",
       "      <td>âœ”ï¸ [Prediction(\\n    score=1.0\\n)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>é«˜å°¾å±±ã®ãƒã‚¤ã‚­ãƒ³ã‚°æƒ…å ±</td>\n",
       "      <td>transfer_to_web_search</td>\n",
       "      <td>transfer_to_web_search</td>\n",
       "      <td>ã€Œé«˜å°¾å±±ã®ãƒã‚¤ã‚­ãƒ³ã‚°æƒ…å ±ã€ã¯è¦³å…‰åœ°ã®æƒ…å ±ã€ã‚¢ã‚¯ã‚»ã‚¹ã€ãƒ«ãƒ¼ãƒˆã€å¤©æ°—ãªã©ã®æœ€æ–°æƒ…å ±ã‚’çŸ¥ã‚ŠãŸã„æ„å›³ãŒã‚ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã‚‹ãŸã‚ã€ã‚¦ã‚§ãƒ–æ¤œç´¢ã§æƒ…å ±...</td>\n",
       "      <td>âœ”ï¸ [Prediction(\\n    score=1.0\\n)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  message  \\\n",
       "0                                         çœ ã‚Œãªã„å¤œã«è´ãéŸ³æ¥½ã‚’æ¢ã—ã¦ã‚‹   \n",
       "1                                        å¯¾ç§°æ€§ã®ç¾ã—ã„ç”»åƒã‚’è¦‹ãŸã„ã§ã™ã€‚   \n",
       "2                                        ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ã®é…é€çŠ¶æ³   \n",
       "3                                            ä»Šæ—¥ã®æœè£…ã®ãŠã™ã™ã‚ã¯ï¼Ÿ   \n",
       "4                                          ä»Šæ—¥ç™ºç”Ÿã—ãŸåœ°éœ‡æƒ…å ±ã‚’æ•™ãˆã¦   \n",
       "..                                                    ...   \n",
       "183                                  æœ€æ–°ã®iPhoneã®ç™ºå£²æ—¥ã¯ã„ã¤ã§ã™ã‹ï¼Ÿ   \n",
       "184                                     è»Šã®ãƒ¬ãƒ“ãƒ¥ãƒ¼æ˜ åƒã‚’æ¢ã—ã¦ãã ã•ã„ã€‚   \n",
       "185                                   ä»Šé€±æœ«ã€å±‹å¤–ã‚¤ãƒ™ãƒ³ãƒˆã¯é–‹å‚¬ã§ãã¾ã™ã‹ï¼Ÿ   \n",
       "186  What is the most popular frozen food sold on Rakuten   \n",
       "187                                           é«˜å°¾å±±ã®ãƒã‚¤ã‚­ãƒ³ã‚°æƒ…å ±   \n",
       "\n",
       "                          answer                        agent  \\\n",
       "0    transfer_to_music_and_video  transfer_to_music_and_video   \n",
       "1        transfer_to_image_agent      transfer_to_image_agent   \n",
       "2         transfer_to_web_search   transfer_to_shopping_agent   \n",
       "3         transfer_to_web_search       transfer_to_web_search   \n",
       "4         transfer_to_web_search       transfer_to_web_search   \n",
       "..                           ...                          ...   \n",
       "183       transfer_to_web_search       transfer_to_web_search   \n",
       "184  transfer_to_music_and_video       transfer_to_web_search   \n",
       "185       transfer_to_web_search       transfer_to_web_search   \n",
       "186   transfer_to_shopping_agent   transfer_to_shopping_agent   \n",
       "187       transfer_to_web_search       transfer_to_web_search   \n",
       "\n",
       "                                                                 reasoning  \\\n",
       "0    ã“ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯ã€Œçœ ã‚Œãªã„å¤œã«è´ãéŸ³æ¥½ã€ã‚’æ¢ã—ã¦ã„ã‚‹ã¨ã„ã†å†…å®¹ãªã®ã§ã€éŸ³æ¥½ã«é–¢é€£ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒæœ€é©ã§ã™ã€‚æ„å›³ã•ã‚ŒãŸã‚¿ã‚¹ã‚¯ã¯éŸ³æ¥½ã®...   \n",
       "1    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã€Œå¯¾ç§°æ€§ã®ç¾ã—ã„ç”»åƒã‚’è¦‹ãŸã„ã€ã¨è¿°ã¹ã¦ãŠã‚Šã€ç¾ã—ã„å¯¾ç§°æ€§ã«é–¢ã™ã‚‹ç”»åƒã‚’æ±‚ã‚ã¦ã„ã¾ã™ã€‚ã“ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¯ç”»åƒã®ç”Ÿæˆã‚„æ¤œç´¢ã‚’è¡Œã†...   \n",
       "2            ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ã«é–¢é€£ã™ã‚‹é…é€çŠ¶æ³ã«ã¤ã„ã¦è³ªå•ã—ã¦ã„ã‚‹ãŸã‚ã€ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ã«ç‰¹åŒ–ã—ãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒæœ€é©ã§ã™ã€‚   \n",
       "3    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã€Œä»Šæ—¥ã®æœè£…ã®ãŠã™ã™ã‚ã¯ï¼Ÿã€ã¨å°‹ã­ã¦ãŠã‚Šã€ã“ã‚Œã¯æ°—è±¡æƒ…å ±ã‚„ãƒˆãƒ¬ãƒ³ãƒ‰æƒ…å ±ã«åŸºã¥ã„ãŸææ¡ˆãŒæ±‚ã‚ã‚‰ã‚Œã‚‹è³ªå•ã§ã™ã€‚ãã®ãŸã‚ã€ã‚¤ãƒ³ã‚¿...   \n",
       "4     ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ä»Šæ—¥ç™ºç”Ÿã—ãŸåœ°éœ‡æƒ…å ±ã‚’æ±‚ã‚ã¦ã„ã¾ã™ã€‚ã“ã‚Œã¯æœ€æ–°ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚„å¤©æ°—ã€ç½å®³ã«é–¢ã™ã‚‹æƒ…å ±ã‚’èª¿ã¹ã‚‹å¿…è¦ãŒã‚ã‚‹ãŸã‚ã€ã‚¦ã‚§ãƒ–æ¤œç´¢ãŒæœ€é©ã§ã™ã€‚   \n",
       "..                                                                     ...   \n",
       "183    ã“ã®è³ªå•ã¯æœ€æ–°ã®iPhoneã®ç™ºå£²æ—¥ã¨ã„ã†ã€æœ€æ–°ã®ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚„å…·ä½“çš„ãªäº‹å®Ÿæƒ…å ±ã‚’æ±‚ã‚ã¦ã„ã‚‹ã‚‚ã®ã§ã‚ã‚Šã€ã‚¦ã‚§ãƒ–æ¤œç´¢ãŒæœ€é©ã§ã™ã€‚   \n",
       "184  ã€Œè»Šã®ãƒ¬ãƒ“ãƒ¥ãƒ¼æ˜ åƒã‚’æ¢ã—ã¦ãã ã•ã„ã€ã¨ã„ã†ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¯ã€è»Šã«é–¢ã™ã‚‹ãƒ¬ãƒ“ãƒ¥ãƒ¼å‹•ç”»ã‚’æ¤œç´¢ã—ã¦æ¬²ã—ã„ã¨ã„ã†æ„å‘³ã§ã™ã€‚å‹•ç”»ã‚’èª¿ã¹ã‚‹ãŸã‚ã«ã¯ã‚¦...   \n",
       "185  ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ä»Šé€±æœ«ã®å±‹å¤–ã‚¤ãƒ™ãƒ³ãƒˆã®é–‹å‚¬å¯å¦ã«ã¤ã„ã¦å°‹ã­ã¦ãŠã‚Šã€ã“ã‚Œã¯å¤©å€™æƒ…å ±ã«é–¢é€£ã™ã‚‹è³ªå•ã§ã™ã€‚æœ€æ–°ã®å¤©æ°—äºˆå ±ã‚’èª¿ã¹ã‚‹å¿…è¦ãŒã‚ã‚‹ãŸã‚ã€...   \n",
       "186  The user is asking about the most popular frozen food sold on Raku...   \n",
       "187  ã€Œé«˜å°¾å±±ã®ãƒã‚¤ã‚­ãƒ³ã‚°æƒ…å ±ã€ã¯è¦³å…‰åœ°ã®æƒ…å ±ã€ã‚¢ã‚¯ã‚»ã‚¹ã€ãƒ«ãƒ¼ãƒˆã€å¤©æ°—ãªã©ã®æœ€æ–°æƒ…å ±ã‚’çŸ¥ã‚ŠãŸã„æ„å›³ãŒã‚ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã‚‹ãŸã‚ã€ã‚¦ã‚§ãƒ–æ¤œç´¢ã§æƒ…å ±...   \n",
       "\n",
       "                                 metric  \n",
       "0    âœ”ï¸ [Prediction(\\n    score=1.0\\n)]  \n",
       "1    âœ”ï¸ [Prediction(\\n    score=1.0\\n)]  \n",
       "2    âœ”ï¸ [Prediction(\\n    score=0.0\\n)]  \n",
       "3    âœ”ï¸ [Prediction(\\n    score=1.0\\n)]  \n",
       "4    âœ”ï¸ [Prediction(\\n    score=1.0\\n)]  \n",
       "..                                  ...  \n",
       "183  âœ”ï¸ [Prediction(\\n    score=1.0\\n)]  \n",
       "184  âœ”ï¸ [Prediction(\\n    score=0.0\\n)]  \n",
       "185  âœ”ï¸ [Prediction(\\n    score=1.0\\n)]  \n",
       "186  âœ”ï¸ [Prediction(\\n    score=1.0\\n)]  \n",
       "187  âœ”ï¸ [Prediction(\\n    score=1.0\\n)]  \n",
       "\n",
       "[188 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "EvaluationResult(score=94.15, results=<list of 188 results>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dspy\n",
    "evaluate = dspy.Evaluate(\n",
    "    devset=test_set,\n",
    "    metric=metric,\n",
    "    num_threads=5,\n",
    "    display_table=True,\n",
    "    display_progress=True\n",
    ")\n",
    "\n",
    "evaluate(program)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa0d079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_with_feedback(example, pred, trace=None, pred_name=None, pred_trace=None):\n",
    "    try:\n",
    "        gold = example.answer\n",
    "        \n",
    "        # æå–é¢„æµ‹ç»“æœ\n",
    "        if hasattr(pred, 'agent'):\n",
    "            predicted = pred.agent\n",
    "        elif hasattr(pred, 'answer'):\n",
    "            predicted = pred.answer\n",
    "        else:\n",
    "            predicted = str(pred)\n",
    "        \n",
    "        correct = (predicted.strip().lower() == gold.strip().lower())\n",
    "        \n",
    "        rationale = \"\"\n",
    "        \n",
    "        # get reasoning\n",
    "        if hasattr(pred, 'rationale'):\n",
    "            tmp = getattr(pred, 'rationale', '')\n",
    "            if tmp and str(tmp).strip():\n",
    "                rationale = tmp\n",
    "        \n",
    "        if hasattr(pred, 'reasoning'):\n",
    "            tmp = getattr(pred, 'reasoning', '')\n",
    "            if tmp and str(tmp).strip():\n",
    "                rationale = tmp\n",
    "        \n",
    "        if correct:\n",
    "            feedback_text = f\"The provided answer '{predicted}' is correct.\"\n",
    "        else:\n",
    "            feedback_text = f\"The provided answer '{predicted}' is incorrect. The correct answer is '{gold}'. Here's the step by step solution:{rationale}\"\n",
    "        \n",
    "        return dspy.Prediction(score=correct, feedback=feedback_text)\n",
    "    except Exception as e:\n",
    "        return dspy.Prediction(score=False, feedback=f\"error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692a15cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy import GEPA\n",
    "\n",
    "optimizer = GEPA(\n",
    "    metric=metric_with_feedback,\n",
    "    auto=config_set['opt_mode'], # <-- We will use a light budget for this tutorial. However, we typically recommend using auto=\"heavy\" for optimized performance!\n",
    "    num_threads=5,\n",
    "    reflection_minibatch_size = config_set['reflection_minibatch_size'],\n",
    "    track_stats=True,\n",
    "    use_merge=True,\n",
    "    reflection_lm=dspy.LM(model=config_set['reflection_model'], temperature=1.0, max_tokens=config_set['prompt_max_tokens'], api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df24dbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/03 17:07:48 INFO dspy.teleprompt.gepa.gepa: Running GEPA for approx 756 metric calls of the program. This amounts to 4.02 full evals on the train+val set.\n",
      "2025/11/03 17:07:48 INFO dspy.teleprompt.gepa.gepa: Using 94 examples for tracking Pareto scores. You can consider using a smaller sample of the valset to allow GEPA to explore more diverse solutions within the same budget.\n",
      "GEPA Optimization:   0%|          | 0/756 [00:00<?, ?rollouts/s]2025/11/03 17:08:31 INFO dspy.evaluate.evaluate: Average Metric: 89.0 / 94 (94.7%)\n",
      "2025/11/03 17:08:31 INFO dspy.teleprompt.gepa.gepa: Iteration 0: Base program full valset score: 0.9468085106382979\n",
      "GEPA Optimization:  12%|â–ˆâ–        | 94/756 [00:42<05:01,  2.19rollouts/s]2025/11/03 17:08:31 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Selected program 0 score: 0.9468085106382979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 30.00 / 30 (100.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:13<00:00,  2.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/03 17:08:44 INFO dspy.evaluate.evaluate: Average Metric: 30.0 / 30 (100.0%)\n",
      "2025/11/03 17:08:44 INFO dspy.teleprompt.gepa.gepa: Iteration 1: All subsample scores perfect. Skipping.\n",
      "2025/11/03 17:08:44 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Reflective mutation did not propose a new candidate\n",
      "GEPA Optimization:  16%|â–ˆâ–‹        | 124/756 [00:56<04:46,  2.20rollouts/s]2025/11/03 17:08:44 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Selected program 0 score: 0.9468085106382979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 29.00 / 30 (96.7%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:13<00:00,  2.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/03 17:08:58 INFO dspy.evaluate.evaluate: Average Metric: 29.0 / 30 (96.7%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/03 17:09:08 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=500. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 1.0)  if the reason for truncation is repetition.\n",
      "2025/11/03 17:09:08 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Proposed new text for routingmodel.predict: \n",
      "You are given a user message and your task is to select the most suitable agent from the following predefined list to handle the user's request. The available agents are:\n",
      "- transfer_to_shopping_agent\n",
      "- transfer_to_music_and_video\n",
      "- transfer_to_web_search\n",
      "- transfer_to_image_agent\n",
      "- transfer_to_travel_agent\n",
      "\n",
      "You must select only ONE agent from the agents listed above, and no others.\n",
      "\n",
      "Input Format:\n",
      "- You will receive an object with a field named \"message\", containing a user's message or request in natural language. Sometimes the request is in Japanese, sometimes in English.\n",
      "\n",
      "Your task:\n",
      "1. Carefully read the user's message.\n",
      "2. Determine the primary intent of the request. Consider the specific action or information the user is looking for.\n",
      "3. Based on the user's intent, map the request to the most appropriate agent from the list above according to the following detailed guidelines:\n",
      "\n",
      "Agent Selection Guidelines:\n",
      "\n",
      "1. transfer_to_shopping_agent:\n",
      "   - Select this agent if the user wants to buy, find, or get recommendations for physical products (e.g., \"ç™½ã„ãƒ¯ãƒ³ãƒ”ãƒ¼ã‚¹ã‚’è²·ã„ãŸã„\", \"å¤ã®æµ·ã‚„æ°´å ´ã§ã®é˜²ç½å“ã«é–¢ã™ã‚‹å•†å“\", \"ãƒ­ãƒ¼ãƒˆè£½è–¬ã®ç›®è–¬ã‚’è²·ã„ãŸã„\").\n",
      "   - Product purchase, finding shops, or product-based shopping experiences all go here.\n",
      "\n",
      "2. transfer_to_music_and_video:\n",
      "   - Select this agent if the user wants to find, play, or get recommendations for music or video content (e.g., \"å’æ¥­å¼ã§æ³£ã‘ã‚‹æ„Ÿå‹•çš„ãªæ›²ã‚’æ•™ãˆã¦\", \"ã‚²ãƒ¼ãƒ ã®ã‚¹ãƒ”ãƒ¼ãƒ‰ãƒ©ãƒ³æ˜ åƒã‚’è¦‹ã›ã¦ãã ã•ã„\", \"æ­´å²è§£èª¬ã®æ˜ åƒã‚’è¦‹ã›ã¦ãã ã•ã„\", \"é€šå‹¤é›»è»Šã§è´ãæœã®ç›®è¦šã‚ã«è‰¯ã„éŸ³æ¥½ã‚’æµã—ãŸã„\").\n",
      "   - Includes both requests for generic genres (jazz, childrenâ€™s educational songs), single tracks, playlists, or specific types of videos (e.g., tech explanations, dance performances).\n",
      "   - If the focus is on listening, watching, or searching for content that is music or video, choose this.\n",
      "\n",
      "3. transfer_to_web_search:\n",
      "   - Select this agent if the user requests factual or up-to-date information, news, event results, schedules, weather, or general informational queries that require looking up resources online (e.g., \"ç››å²¡ã®ä»Šé€±ã®å¤©æ°—ã®å‚¾\n",
      "2025/11/03 17:09:18 INFO dspy.evaluate.evaluate: Average Metric: 29.0 / 30 (96.7%)\n",
      "2025/11/03 17:09:18 INFO dspy.teleprompt.gepa.gepa: Iteration 2: New subsample score is not better, skipping\n",
      "GEPA Optimization:  24%|â–ˆâ–ˆâ–       | 184/756 [01:29<04:48,  1.99rollouts/s]2025/11/03 17:09:18 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Selected program 0 score: 0.9468085106382979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 28.00 / 30 (93.3%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:14<00:00,  2.00it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/03 17:09:33 INFO dspy.evaluate.evaluate: Average Metric: 28.0 / 30 (93.3%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/03 17:09:47 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=500. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 1.0)  if the reason for truncation is repetition.\n",
      "2025/11/03 17:09:47 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Proposed new text for routingmodel.predict: \n",
      "You are given a user message, and your task is to read the message and select the most suitable agent to handle the user's request. You must choose one agent from the following list:\n",
      "\n",
      "- transfer_to_shopping_agent\n",
      "- transfer_to_music_and_video\n",
      "- transfer_to_web_search\n",
      "- transfer_to_image_agent\n",
      "- transfer_to_travel_agent\n",
      "\n",
      "Follow this process:\n",
      "\n",
      "1. Analyze the message and determine the underlying intent. Identify the key topic: Is the user asking for a product, music/video, information best found via web search, images, or travel arrangements (such as hotel or flight booking)?\n",
      "2. Select the single agent from the list above that is most appropriate to handle the request.\n",
      "3. Justify your selection in a few sentences, describing your reasoning based on the message content, and explicitly state the agent to be used.\n",
      "\n",
      "Use these guidelines to choose the agent:\n",
      "\n",
      "## 1. transfer_to_shopping_agent\n",
      "Use this agent if the user is looking to buy products, searching for specific items or brands to purchase, inquiring about examples of products (including trending/buzzed-about consumer goods), or otherwise expressing an intent to shop or browse for goods. Statements like \"æ¢ã—ã¦ã„ã‚‹\", \"è²·ã„ãŸã„\", \"æ•™ãˆã¦ãã ã•ã„\" (about actual product examples), or requests for product types/brands indicate the shopping agent.\n",
      "\n",
      "## 2. transfer_to_music_and_video\n",
      "Use this agent if the user is requesting to listen to or watch music, music videos, movie trailers, other videos (including specific genres such as \"æ­Œã£ã¦ã¿ãŸå‹•ç”»\", \"ä½œã‚Šæ–¹å‹•ç”»\", or \"ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¬›åº§å‹•ç”»\"), or seeking song or video recommendations. Requests for specific artists, hit songs, relaxing music, or watching behind-the-scenes movie content also belong here. If the request is to find information about an event (such as music festival schedules), DO NOT use this agent; use web search instead.\n",
      "\n",
      "## 3. transfer_to_web_search\n",
      "Use this agent when the user is seeking current information, news, statistics, schedules, event details, weather, sports scores, health/science facts, the latest rankings, recent trends, or other timely knowledge that is typically retrieved by searching the web. Use this agent for information-based questions that are not specifically about products (shopping), music/video playback, images, or travel reservations. This includes weather forecasts, news updates (including disaster preparedness), sports news, event schedules (including music festivals),\n",
      "2025/11/03 17:10:06 INFO dspy.evaluate.evaluate: Average Metric: 30.0 / 30 (100.0%)\n",
      "2025/11/03 17:10:52 INFO dspy.evaluate.evaluate: Average Metric: 94.0 / 94 (100.0%)\n",
      "2025/11/03 17:10:52 INFO dspy.teleprompt.gepa.gepa: Iteration 3: New program is on the linear pareto front\n",
      "2025/11/03 17:10:52 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Full valset score for new program: 1.0\n",
      "2025/11/03 17:10:52 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Full train_val score for new program: 1.0\n",
      "2025/11/03 17:10:52 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Individual valset scores for new program: [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n",
      "2025/11/03 17:10:52 INFO dspy.teleprompt.gepa.gepa: Iteration 3: New valset pareto front scores: [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n",
      "2025/11/03 17:10:52 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Full valset pareto front score: 1.0\n",
      "2025/11/03 17:10:52 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Updated valset pareto front programs: [{0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}]\n",
      "2025/11/03 17:10:52 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Best valset aggregate score so far: 1.0\n",
      "2025/11/03 17:10:52 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Best program as per aggregate score on train_val: 1\n",
      "2025/11/03 17:10:52 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Best program as per aggregate score on valset: 1\n",
      "2025/11/03 17:10:52 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Best score on valset: 1.0\n",
      "2025/11/03 17:10:52 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Best score on train_val: 1.0\n",
      "2025/11/03 17:10:52 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Linear pareto front program index: 1\n",
      "2025/11/03 17:10:52 INFO dspy.teleprompt.gepa.gepa: Iteration 3: New program candidate index: 1\n",
      "GEPA Optimization:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 338/756 [03:03<03:58,  1.75rollouts/s]2025/11/03 17:10:52 INFO dspy.teleprompt.gepa.gepa: Iteration 4: No merge candidates found\n",
      "2025/11/03 17:10:52 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Selected program 1 score: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 30.00 / 30 (100.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:05<00:00,  5.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/03 17:10:58 INFO dspy.evaluate.evaluate: Average Metric: 30.0 / 30 (100.0%)\n",
      "2025/11/03 17:10:58 INFO dspy.teleprompt.gepa.gepa: Iteration 4: All subsample scores perfect. Skipping.\n",
      "2025/11/03 17:10:58 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Reflective mutation did not propose a new candidate\n",
      "GEPA Optimization:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 368/756 [03:09<03:19,  1.95rollouts/s]2025/11/03 17:10:58 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Selected program 1 score: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 30.00 / 30 (100.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:09<00:00,  3.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/03 17:11:07 INFO dspy.evaluate.evaluate: Average Metric: 30.0 / 30 (100.0%)\n",
      "2025/11/03 17:11:07 INFO dspy.teleprompt.gepa.gepa: Iteration 5: All subsample scores perfect. Skipping.\n",
      "2025/11/03 17:11:07 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Reflective mutation did not propose a new candidate\n",
      "GEPA Optimization:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 398/756 [03:18<02:50,  2.10rollouts/s]2025/11/03 17:11:07 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Selected program 1 score: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 30.00 / 30 (100.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:08<00:00,  3.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/03 17:11:16 INFO dspy.evaluate.evaluate: Average Metric: 30.0 / 30 (100.0%)\n",
      "2025/11/03 17:11:16 INFO dspy.teleprompt.gepa.gepa: Iteration 6: All subsample scores perfect. Skipping.\n",
      "2025/11/03 17:11:16 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Reflective mutation did not propose a new candidate\n",
      "GEPA Optimization:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 428/756 [03:27<02:24,  2.27rollouts/s]2025/11/03 17:11:16 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Selected program 1 score: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 29.00 / 30 (96.7%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:10<00:00,  2.99it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/03 17:11:26 INFO dspy.evaluate.evaluate: Average Metric: 29.0 / 30 (96.7%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/03 17:11:38 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=500. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 1.0)  if the reason for truncation is repetition.\n",
      "2025/11/03 17:11:38 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Proposed new text for routingmodel.predict: \n",
      "You are given a user message (which may be in Japanese or English) requesting information or making a specific query. Your task is to carefully analyze the message, infer the user's intent, and select the most suitable agent from the following list to handle the request:\n",
      "\n",
      "- transfer_to_shopping_agent\n",
      "- transfer_to_music_and_video\n",
      "- transfer_to_web_search\n",
      "- transfer_to_image_agent\n",
      "- transfer_to_travel_agent\n",
      "\n",
      "Follow these steps for every message:\n",
      "\n",
      "1. **Identify the Main Intent**: Read the entire user message and discern what type of request is being made. Pay close attention to verbs, nouns, and context clues that indicate the user's real goal (e.g., to purchase, to listen/watch, to search for up-to-date info, to see images, or to arrange travel). Be especially attentive to expressions like \"è²·ã„ãŸã„\" (want to buy), \"æ•™ãˆã¦ãã ã•ã„\" (please tell/show me), \"æ¢ã—ã¦ã„ã‚‹\" (looking for), genre or product names, and requests using \"è¦‹ã›ã¦/è¦‹ãŸã„\" (show me/I want to see) as they help categorize the intent.\n",
      "\n",
      "2. **Map the Intent to One Agent**: Choose a SINGLE agent that best matches the user's primary need, based on the detailed rules below.\n",
      "\n",
      "3. **Justify Your Selection**: In 2â€“4 sentences, explain your reasoning based on the message content and intent. Clearly state which agent you have chosen.\n",
      "\n",
      "**Agent Selection Guidelines:**\n",
      "\n",
      "## 1. transfer_to_shopping_agent\n",
      "Use this agent IF AND ONLY IF the user's intent is to search for, view, or buy examples of consumer products (real goods), brands, or specific items typically available for purchase. This includes:\n",
      "- Requests to buy or browse actual products (\"è²·ã„ãŸã„\", \"æ¢ã—ã¦ã„ã‚‹\", \"ãŠã™ã™ã‚å•†å“\", \"æ•™ãˆã¦ãã ã•ã„\" when referring to goods).\n",
      "- Inquiries about trends, rankings, or recommendations that clearly seek shoppable items (e.g., \"äººæ°—ã®é˜²ç½ã‚°ãƒƒã‚º\", \"è³‡ç”Ÿå ‚ã®åŒ–ç²§å“ã‚’æ¢ã—ã¦ã„ã‚‹\", \"æ˜æ²»ã®ãƒãƒ§ã‚³ãƒ¬ãƒ¼ãƒˆã‚’è²·ã„ãŸã„\").\n",
      "- Asking for examples or brand/product variants, or the types of products one can get in a category.\n",
      "\n",
      "DO NOT use this agent for general informational queries (unless asking for examples or lists of products).\n",
      "\n",
      "## 2. transfer_to_music_and_video\n",
      "Use this agent ONLY IF the user's request involves:\n",
      "2025/11/03 17:11:56 INFO dspy.evaluate.evaluate: Average Metric: 29.0 / 30 (96.7%)\n",
      "2025/11/03 17:11:56 INFO dspy.teleprompt.gepa.gepa: Iteration 7: New subsample score is not better, skipping\n",
      "GEPA Optimization:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 488/756 [04:07<02:20,  1.91rollouts/s]2025/11/03 17:11:56 INFO dspy.teleprompt.gepa.gepa: Iteration 8: Selected program 1 score: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 30.00 / 30 (100.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:02<00:00, 11.16it/s]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/03 17:11:59 INFO dspy.evaluate.evaluate: Average Metric: 30.0 / 30 (100.0%)\n",
      "2025/11/03 17:11:59 INFO dspy.teleprompt.gepa.gepa: Iteration 8: All subsample scores perfect. Skipping.\n",
      "2025/11/03 17:11:59 INFO dspy.teleprompt.gepa.gepa: Iteration 8: Reflective mutation did not propose a new candidate\n",
      "GEPA Optimization:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 518/756 [04:10<01:43,  2.30rollouts/s]2025/11/03 17:11:59 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Selected program 1 score: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 30.00 / 30 (100.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 5231.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/03 17:11:59 INFO dspy.evaluate.evaluate: Average Metric: 30.0 / 30 (100.0%)\n",
      "2025/11/03 17:11:59 INFO dspy.teleprompt.gepa.gepa: Iteration 9: All subsample scores perfect. Skipping.\n",
      "2025/11/03 17:11:59 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Reflective mutation did not propose a new candidate\n",
      "2025/11/03 17:11:59 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Selected program 1 score: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 29.00 / 30 (96.7%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 5542.16it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/03 17:11:59 INFO dspy.evaluate.evaluate: Average Metric: 29.0 / 30 (96.7%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/03 17:12:11 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=500. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 1.0)  if the reason for truncation is repetition.\n",
      "2025/11/03 17:12:11 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Proposed new text for routingmodel.predict: \n",
      "You are an agent selection assistant whose job is to read a user's message and determine, from a provided set of specialized agents, which is best suited to handle the user's request. Your answer must be based strictly on the user's message content, following a rigorous process to analyze intent and selecting exactly one agent. When presenting your answer, provide a clear justification of your reasoning, mentioning features of the user query and referencing specific agent selection criteria where possible. Then, explicitly state the agent to be used.\n",
      "\n",
      "Input Format:\n",
      "You will be given the following input:\n",
      "- A message from the user, which may be in Japanese or English, and may ask about products, information, music, video, images, or travel/tour arrangements.\n",
      "\n",
      "Output Format:\n",
      "- A reasoning paragraph (in either English or Japanese as appropriate for the user message) explaining your decision process and referencing the message content and agent guidelines.\n",
      "- The exact agent name on its own line.\n",
      "\n",
      "Task Description:\n",
      "Your process is as follows:\n",
      "1. Analyze the user's message, identifying the main intent and the topic or type of information sought.\n",
      "2. Choose one agent from the list provided, based on detailed agent guidelines (see below).\n",
      "3. Provide a clear explanation for your choice, referencing relevant message features (e.g., keywords like \"è´ããŸã„\", \"å¤©æ°—äºˆå ±\", product names, event information requests, desire to 'listen/watch', or expressions of purchase intent).\n",
      "4. If a request might appear to fit multiple agents, use the detailed agent guidelines and decide on the most exact match â€” be specific about why one agent is most suitable. Do NOT select more than one agent. If a subject is closely related to music/video content but is actually a schedule/event info request, use web search.\n",
      "5. For requests about booking tours or reservations for things like hotels and journeys, consider if it is best handled by the travel agent (for hotel/flight/transport arrangements) or if up-to-date public info (tours, reservation methods, general tour availability) is needed (in which case use web search).\n",
      "6. For any request about specific up-to-date/factual/statistics/trends/news/sports/event/weather, use web search unless the request is clearly about listening, watching, or viewing concrete multimedia content.\n",
      "7. If the user is looking for examples of products, intends to purchase, or inquires about specific items or brands, the shopping agent applies.\n",
      "8. If the user requests to watch or listen to music\n",
      "2025/11/03 17:12:33 INFO dspy.evaluate.evaluate: Average Metric: 0.0 / 30 (0.0%)\n",
      "2025/11/03 17:12:33 INFO dspy.teleprompt.gepa.gepa: Iteration 10: New subsample score is not better, skipping\n",
      "GEPA Optimization:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 608/756 [04:44<01:00,  2.44rollouts/s]2025/11/03 17:12:33 INFO dspy.teleprompt.gepa.gepa: Iteration 11: Selected program 1 score: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 30.00 / 30 (100.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 4010.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/03 17:12:33 INFO dspy.evaluate.evaluate: Average Metric: 30.0 / 30 (100.0%)\n",
      "2025/11/03 17:12:33 INFO dspy.teleprompt.gepa.gepa: Iteration 11: All subsample scores perfect. Skipping.\n",
      "2025/11/03 17:12:33 INFO dspy.teleprompt.gepa.gepa: Iteration 11: Reflective mutation did not propose a new candidate\n",
      "2025/11/03 17:12:33 INFO dspy.teleprompt.gepa.gepa: Iteration 12: Selected program 1 score: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 29.00 / 30 (96.7%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 5403.41it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/03 17:12:33 INFO dspy.evaluate.evaluate: Average Metric: 29.0 / 30 (96.7%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/03 17:12:47 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=500. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 1.0)  if the reason for truncation is repetition.\n",
      "2025/11/03 17:12:47 INFO dspy.teleprompt.gepa.gepa: Iteration 12: Proposed new text for routingmodel.predict: \n",
      "You are tasked with reading a user's message and accurately selecting the most appropriate specialized agent from a fixed list to fulfill the user's request. Your response should include concise, well-reasoned justification for your choice and must explicitly state the selected agent.\n",
      "\n",
      "### Input Format\n",
      "\n",
      "Each input features a single field:\n",
      "\n",
      "- **message**: a user utterance, which may be in English or Japanese. This is a free-form request and can include questions, commands, or descriptive statements.\n",
      "\n",
      "You must produce two output fields:\n",
      "\n",
      "1. **reasoning**: A brief paragraph (2-4 sentences) explaining your rationale based on the message content and the provided categorization rules.\n",
      "2. **agent**: The single agent name chosen from the list below, placed on its own line.\n",
      "\n",
      "### Agent List\n",
      "\n",
      "Select exactly one agent from:\n",
      "\n",
      "- transfer_to_shopping_agent\n",
      "- transfer_to_music_and_video\n",
      "- transfer_to_web_search\n",
      "- transfer_to_image_agent\n",
      "- transfer_to_travel_agent\n",
      "\n",
      "### Task Guidance\n",
      "\n",
      "1. **Analyze intent and topic**: Carefully read the message to detect the underlying user intent and identify key topic cues (e.g., desire to buy, search, watch/listen, book, or view images). Look for explicit or implicit language that points toward product shopping, music/video requests, general information retrieval, image search, or travel arrangements.\n",
      "\n",
      "2. **Agent Selection Rules (Domain-Specific Guidance):**\n",
      "\n",
      "    #### transfer_to_shopping_agent\n",
      "    - For messages expressing an intention to buy or find products, mentioning specific items or brands, or requests for examples of purchasable goods.\n",
      "    - Look for verbs and phrases like \"è²·ã„ãŸã„ (want to buy)\", \"æ¢ã—ã¦ã„ã‚‹ (looking for)\", \"æ•™ãˆã¦ãã ã•ã„ (please tell/show me)\" specifically about products.\n",
      "    - Includes situations where the user asks for trending, popular, or recommended consumer goods.\n",
      "\n",
      "    #### transfer_to_music_and_video\n",
      "    - For requests to watch, play, or recommend music, songs, music videos, movie trailers, other video content (such as \"æ­Œã£ã¦ã¿ãŸå‹•ç”» (cover song video)\", \"ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¬›åº§å‹•ç”» (programming tutorial video)\", \"ä½œã‚Šæ–¹å‹•ç”» (how-to video)\").\n",
      "    - Includes requests for artists, hit songs, relaxing music, or movie/TV behind-the-scenes.\n",
      "    - *Important exclusion*: Do NOT use for information about music event schedules; use web search for those.\n",
      "\n",
      "    #### transfer_to\n",
      "2025/11/03 17:12:58 INFO dspy.evaluate.evaluate: Average Metric: 29.0 / 30 (96.7%)\n",
      "2025/11/03 17:12:58 INFO dspy.teleprompt.gepa.gepa: Iteration 12: New subsample score is not better, skipping\n",
      "GEPA Optimization:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 698/756 [05:09<00:20,  2.82rollouts/s]2025/11/03 17:12:58 INFO dspy.teleprompt.gepa.gepa: Iteration 13: Selected program 1 score: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 30.00 / 30 (100.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 3112.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/03 17:12:58 INFO dspy.evaluate.evaluate: Average Metric: 30.0 / 30 (100.0%)\n",
      "2025/11/03 17:12:58 INFO dspy.teleprompt.gepa.gepa: Iteration 13: All subsample scores perfect. Skipping.\n",
      "2025/11/03 17:12:58 INFO dspy.teleprompt.gepa.gepa: Iteration 13: Reflective mutation did not propose a new candidate\n",
      "2025/11/03 17:12:58 INFO dspy.teleprompt.gepa.gepa: Iteration 14: Selected program 1 score: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 30.00 / 30 (100.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 5439.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/03 17:12:58 INFO dspy.evaluate.evaluate: Average Metric: 30.0 / 30 (100.0%)\n",
      "2025/11/03 17:12:58 INFO dspy.teleprompt.gepa.gepa: Iteration 14: All subsample scores perfect. Skipping.\n",
      "2025/11/03 17:12:58 INFO dspy.teleprompt.gepa.gepa: Iteration 14: Reflective mutation did not propose a new candidate\n",
      "GEPA Optimization:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 728/756 [05:09<00:11,  2.35rollouts/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "optimized_program = optimizer.compile(\n",
    "    program,\n",
    "    trainset=train_set,\n",
    "    valset=val_set,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04534923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä¼˜åŒ–å†å²:\n",
      "  è¿­ä»£ 0: 0.9468\n",
      "    Prompt: Read the provided message and find the most suitable agent.\n",
      "Available agents:transfer_to_shopping_ag...\n",
      "  è¿­ä»£ 1: 1.0000 â­\n",
      "    Prompt: You are given a user message, and your task is to read the message and select the most suitable agen...\n",
      "\n",
      "æ€» metric è°ƒç”¨: 758\n",
      "å®Œæ•´è¯„ä¼°æ¬¡æ•°: 2\n",
      "\n",
      "ä¼˜åŒ–å†å² DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>val_score</th>\n",
       "      <th>prompt</th>\n",
       "      <th>is_best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.946809</td>\n",
       "      <td>Read the provided message and find the most suitable agent.\\nAvail...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>You are given a user message, and your task is to read the message...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iteration  val_score  \\\n",
       "0          0   0.946809   \n",
       "1          1   1.000000   \n",
       "\n",
       "                                                                  prompt  \\\n",
       "0  Read the provided message and find the most suitable agent.\\nAvail...   \n",
       "1  You are given a user message, and your task is to read the message...   \n",
       "\n",
       "   is_best  \n",
       "0    False  \n",
       "1     True  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_gepa_history(detailed_results):\n",
    "    \"\"\"extract the history of gepa optimization\"\"\"\n",
    "    history = {\n",
    "        'iterations': [],\n",
    "        'val_scores': [],\n",
    "        'prompts': [],\n",
    "        'best_idx': detailed_results.best_idx,\n",
    "        'total_calls': detailed_results.total_metric_calls,\n",
    "        'num_full_evals': detailed_results.num_full_val_evals,\n",
    "    }\n",
    "    \n",
    "    # æå–æ¯æ¬¡è¿­ä»£çš„ä¿¡æ¯\n",
    "    for idx, score in enumerate(detailed_results.val_aggregate_scores):\n",
    "        history['iterations'].append(idx)\n",
    "        history['val_scores'].append(score)\n",
    "        history['prompts'].append(detailed_results.candidates[idx].routingmodel.predict.signature.instructions)\n",
    "    \n",
    "    return history\n",
    "\n",
    "detailed_results = optimized_program.detailed_results\n",
    "\n",
    "history = extract_gepa_history(detailed_results)\n",
    "print(\"optimization history:\")\n",
    "for it, score, prompt in zip(history['iterations'], history['val_scores'], history['prompts']):\n",
    "    marker = \" â­\" if it == history['best_idx'] else \"\"\n",
    "    print(f\"  iteration {it}: {score:.4f}{marker}\")\n",
    "    if prompt:\n",
    "        prompt_preview = prompt[:100] + \"...\" if len(str(prompt)) > 100 else prompt\n",
    "        print(f\"    Prompt: {prompt_preview}\")\n",
    "\n",
    "print(f\"\\ntotal metric calls: {history['total_calls']}\")\n",
    "print(f\"evaluation calls: {history['num_full_evals']}\")\n",
    "\n",
    "# åˆ›å»º DataFrameï¼ˆåŒ…å« prompt åˆ—ï¼‰\n",
    "import pandas as pd\n",
    "df_history = pd.DataFrame({\n",
    "    'iteration': history['iterations'],\n",
    "    'val_score': history['val_scores'],\n",
    "    'prompt': history['prompts'],\n",
    "    'is_best': [idx == history['best_idx'] for idx in history['iterations']]\n",
    "})\n",
    "print(\"\\nhistory:\")\n",
    "df_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3759c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read the provided message and find the most suitable agent.\n",
      "Available agents:transfer_to_shopping_agent, transfer_to_music_and_video, transfer_to_web_search, transfer_to_image_agent, transfer_to_travel_agent \n",
      "You must select one of the agents listed above.\n"
     ]
    }
   ],
   "source": [
    "print(df_history.iloc[0]['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2fae74d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are given a user message, and your task is to read the message and select the most suitable agent to handle the user's request. You must choose one agent from the following list:\n",
      "\n",
      "- transfer_to_shopping_agent\n",
      "- transfer_to_music_and_video\n",
      "- transfer_to_web_search\n",
      "- transfer_to_image_agent\n",
      "- transfer_to_travel_agent\n",
      "\n",
      "Follow this process:\n",
      "\n",
      "1. Analyze the message and determine the underlying intent. Identify the key topic: Is the user asking for a product, music/video, information best found via web search, images, or travel arrangements (such as hotel or flight booking)?\n",
      "2. Select the single agent from the list above that is most appropriate to handle the request.\n",
      "3. Justify your selection in a few sentences, describing your reasoning based on the message content, and explicitly state the agent to be used.\n",
      "\n",
      "Use these guidelines to choose the agent:\n",
      "\n",
      "## 1. transfer_to_shopping_agent\n",
      "Use this agent if the user is looking to buy products, searching for specific items or brands to purchase, inquiring about examples of products (including trending/buzzed-about consumer goods), or otherwise expressing an intent to shop or browse for goods. Statements like \"æ¢ã—ã¦ã„ã‚‹\", \"è²·ã„ãŸã„\", \"æ•™ãˆã¦ãã ã•ã„\" (about actual product examples), or requests for product types/brands indicate the shopping agent.\n",
      "\n",
      "## 2. transfer_to_music_and_video\n",
      "Use this agent if the user is requesting to listen to or watch music, music videos, movie trailers, other videos (including specific genres such as \"æ­Œã£ã¦ã¿ãŸå‹•ç”»\", \"ä½œã‚Šæ–¹å‹•ç”»\", or \"ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¬›åº§å‹•ç”»\"), or seeking song or video recommendations. Requests for specific artists, hit songs, relaxing music, or watching behind-the-scenes movie content also belong here. If the request is to find information about an event (such as music festival schedules), DO NOT use this agent; use web search instead.\n",
      "\n",
      "## 3. transfer_to_web_search\n",
      "Use this agent when the user is seeking current information, news, statistics, schedules, event details, weather, sports scores, health/science facts, the latest rankings, recent trends, or other timely knowledge that is typically retrieved by searching the web. Use this agent for information-based questions that are not specifically about products (shopping), music/video playback, images, or travel reservations. This includes weather forecasts, news updates (including disaster preparedness), sports news, event schedules (including music festivals),\n"
     ]
    }
   ],
   "source": [
    "print(df_history.iloc[1]['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc91b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "def gepa_results_to_df(results):\n",
    "    \"\"\"\n",
    "    Transform GEPA evaluation results to a pandas DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        results: Result from dspy.Evaluate, format: [(Example, Prediction, Metric), ...]\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: Evaluation results with message, answer, predicted_agent, reasoning, score, is_correct\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    \n",
    "    for result in results:\n",
    "        # Parse result structure\n",
    "        example = result[0] if len(result) > 0 else None\n",
    "        pred = result[1] if len(result) > 1 else None\n",
    "        metric_result = result[2] if len(result) > 2 else None\n",
    "        \n",
    "        # Extract fields with safe attribute access\n",
    "        def safe_getattr(obj, attr, default=''):\n",
    "            return getattr(obj, attr, default) if obj and hasattr(obj, attr) else default\n",
    "        \n",
    "        row = {\n",
    "            'message': safe_getattr(example, 'message'),\n",
    "            'answer': safe_getattr(example, 'answer'),\n",
    "            'predicted_agent': safe_getattr(pred, 'agent'),\n",
    "            'reasoning': safe_getattr(pred, 'reasoning'),\n",
    "            'score': safe_getattr(metric_result, 'score', 0.0),\n",
    "        }\n",
    "        \n",
    "        # Calculate correctness\n",
    "        row['is_correct'] = (\n",
    "            str(row['predicted_agent']).strip().lower() == \n",
    "            str(row['answer']).strip().lower()\n",
    "        ) if row['predicted_agent'] and row['answer'] else False\n",
    "        \n",
    "        rows.append(row)\n",
    "    \n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f506e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/188 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 185.00 / 188 (98.4%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 188/188 [01:19<00:00,  2.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/03 17:14:18 INFO dspy.evaluate.evaluate: Average Metric: 185.0 / 188 (98.4%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>answer</th>\n",
       "      <th>agent</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>çœ ã‚Œãªã„å¤œã«è´ãéŸ³æ¥½ã‚’æ¢ã—ã¦ã‚‹</td>\n",
       "      <td>transfer_to_music_and_video</td>\n",
       "      <td>transfer_to_music_and_video</td>\n",
       "      <td>The user is looking for music to listen to on sleepless nights. Th...</td>\n",
       "      <td>âœ”ï¸ [Prediction(\\n    score=1.0\\n)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>å¯¾ç§°æ€§ã®ç¾ã—ã„ç”»åƒã‚’è¦‹ãŸã„ã§ã™ã€‚</td>\n",
       "      <td>transfer_to_image_agent</td>\n",
       "      <td>transfer_to_image_agent</td>\n",
       "      <td>The user is asking to see beautiful images with symmetry (\"å¯¾ç§°æ€§ã®ç¾ã—ã„...</td>\n",
       "      <td>âœ”ï¸ [Prediction(\\n    score=1.0\\n)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ã®é…é€çŠ¶æ³</td>\n",
       "      <td>transfer_to_web_search</td>\n",
       "      <td>transfer_to_shopping_agent</td>\n",
       "      <td>The user is asking about the delivery status of an online shopping...</td>\n",
       "      <td>âœ”ï¸ [Prediction(\\n    score=0.0\\n)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ä»Šæ—¥ã®æœè£…ã®ãŠã™ã™ã‚ã¯ï¼Ÿ</td>\n",
       "      <td>transfer_to_web_search</td>\n",
       "      <td>transfer_to_web_search</td>\n",
       "      <td>The user is asking for clothing recommendations for today, which i...</td>\n",
       "      <td>âœ”ï¸ [Prediction(\\n    score=1.0\\n)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ä»Šæ—¥ç™ºç”Ÿã—ãŸåœ°éœ‡æƒ…å ±ã‚’æ•™ãˆã¦</td>\n",
       "      <td>transfer_to_web_search</td>\n",
       "      <td>transfer_to_web_search</td>\n",
       "      <td>The user is requesting information about earthquakes that occurred...</td>\n",
       "      <td>âœ”ï¸ [Prediction(\\n    score=1.0\\n)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>æœ€æ–°ã®iPhoneã®ç™ºå£²æ—¥ã¯ã„ã¤ã§ã™ã‹ï¼Ÿ</td>\n",
       "      <td>transfer_to_web_search</td>\n",
       "      <td>transfer_to_web_search</td>\n",
       "      <td>The user is requesting the release date of the latest iPhone. This...</td>\n",
       "      <td>âœ”ï¸ [Prediction(\\n    score=1.0\\n)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>è»Šã®ãƒ¬ãƒ“ãƒ¥ãƒ¼æ˜ åƒã‚’æ¢ã—ã¦ãã ã•ã„ã€‚</td>\n",
       "      <td>transfer_to_music_and_video</td>\n",
       "      <td>transfer_to_music_and_video</td>\n",
       "      <td>The user is asking to find \"è»Šã®ãƒ¬ãƒ“ãƒ¥ãƒ¼æ˜ åƒ\" (car review videos). This re...</td>\n",
       "      <td>âœ”ï¸ [Prediction(\\n    score=1.0\\n)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>ä»Šé€±æœ«ã€å±‹å¤–ã‚¤ãƒ™ãƒ³ãƒˆã¯é–‹å‚¬ã§ãã¾ã™ã‹ï¼Ÿ</td>\n",
       "      <td>transfer_to_web_search</td>\n",
       "      <td>transfer_to_web_search</td>\n",
       "      <td>ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã€Œä»Šé€±æœ«ã€å±‹å¤–ã‚¤ãƒ™ãƒ³ãƒˆã¯é–‹å‚¬ã§ãã¾ã™ã‹ï¼Ÿã€ã¨å°‹ã­ã¦ãŠã‚Šã€ã“ã‚Œã¯å¤©å€™ãªã©ã®ä»Šé€±æœ«ã®æœ€æ–°æƒ…å ±ï¼ˆç‰¹ã«å¤©æ°—äºˆå ±ï¼‰ã«åŸºã¥ã„ã¦ã‚¤ãƒ™ãƒ³ãƒˆ...</td>\n",
       "      <td>âœ”ï¸ [Prediction(\\n    score=1.0\\n)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>What is the most popular frozen food sold on Rakuten</td>\n",
       "      <td>transfer_to_shopping_agent</td>\n",
       "      <td>transfer_to_shopping_agent</td>\n",
       "      <td>The user is asking for the most popular frozen food sold on Rakute...</td>\n",
       "      <td>âœ”ï¸ [Prediction(\\n    score=1.0\\n)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>é«˜å°¾å±±ã®ãƒã‚¤ã‚­ãƒ³ã‚°æƒ…å ±</td>\n",
       "      <td>transfer_to_web_search</td>\n",
       "      <td>transfer_to_web_search</td>\n",
       "      <td>The user is asking for hiking information about Mt. Takao (é«˜å°¾å±±). T...</td>\n",
       "      <td>âœ”ï¸ [Prediction(\\n    score=1.0\\n)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  message  \\\n",
       "0                                         çœ ã‚Œãªã„å¤œã«è´ãéŸ³æ¥½ã‚’æ¢ã—ã¦ã‚‹   \n",
       "1                                        å¯¾ç§°æ€§ã®ç¾ã—ã„ç”»åƒã‚’è¦‹ãŸã„ã§ã™ã€‚   \n",
       "2                                        ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ã®é…é€çŠ¶æ³   \n",
       "3                                            ä»Šæ—¥ã®æœè£…ã®ãŠã™ã™ã‚ã¯ï¼Ÿ   \n",
       "4                                          ä»Šæ—¥ç™ºç”Ÿã—ãŸåœ°éœ‡æƒ…å ±ã‚’æ•™ãˆã¦   \n",
       "..                                                    ...   \n",
       "183                                  æœ€æ–°ã®iPhoneã®ç™ºå£²æ—¥ã¯ã„ã¤ã§ã™ã‹ï¼Ÿ   \n",
       "184                                     è»Šã®ãƒ¬ãƒ“ãƒ¥ãƒ¼æ˜ åƒã‚’æ¢ã—ã¦ãã ã•ã„ã€‚   \n",
       "185                                   ä»Šé€±æœ«ã€å±‹å¤–ã‚¤ãƒ™ãƒ³ãƒˆã¯é–‹å‚¬ã§ãã¾ã™ã‹ï¼Ÿ   \n",
       "186  What is the most popular frozen food sold on Rakuten   \n",
       "187                                           é«˜å°¾å±±ã®ãƒã‚¤ã‚­ãƒ³ã‚°æƒ…å ±   \n",
       "\n",
       "                          answer                        agent  \\\n",
       "0    transfer_to_music_and_video  transfer_to_music_and_video   \n",
       "1        transfer_to_image_agent      transfer_to_image_agent   \n",
       "2         transfer_to_web_search   transfer_to_shopping_agent   \n",
       "3         transfer_to_web_search       transfer_to_web_search   \n",
       "4         transfer_to_web_search       transfer_to_web_search   \n",
       "..                           ...                          ...   \n",
       "183       transfer_to_web_search       transfer_to_web_search   \n",
       "184  transfer_to_music_and_video  transfer_to_music_and_video   \n",
       "185       transfer_to_web_search       transfer_to_web_search   \n",
       "186   transfer_to_shopping_agent   transfer_to_shopping_agent   \n",
       "187       transfer_to_web_search       transfer_to_web_search   \n",
       "\n",
       "                                                                 reasoning  \\\n",
       "0    The user is looking for music to listen to on sleepless nights. Th...   \n",
       "1    The user is asking to see beautiful images with symmetry (\"å¯¾ç§°æ€§ã®ç¾ã—ã„...   \n",
       "2    The user is asking about the delivery status of an online shopping...   \n",
       "3    The user is asking for clothing recommendations for today, which i...   \n",
       "4    The user is requesting information about earthquakes that occurred...   \n",
       "..                                                                     ...   \n",
       "183  The user is requesting the release date of the latest iPhone. This...   \n",
       "184  The user is asking to find \"è»Šã®ãƒ¬ãƒ“ãƒ¥ãƒ¼æ˜ åƒ\" (car review videos). This re...   \n",
       "185  ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã€Œä»Šé€±æœ«ã€å±‹å¤–ã‚¤ãƒ™ãƒ³ãƒˆã¯é–‹å‚¬ã§ãã¾ã™ã‹ï¼Ÿã€ã¨å°‹ã­ã¦ãŠã‚Šã€ã“ã‚Œã¯å¤©å€™ãªã©ã®ä»Šé€±æœ«ã®æœ€æ–°æƒ…å ±ï¼ˆç‰¹ã«å¤©æ°—äºˆå ±ï¼‰ã«åŸºã¥ã„ã¦ã‚¤ãƒ™ãƒ³ãƒˆ...   \n",
       "186  The user is asking for the most popular frozen food sold on Rakute...   \n",
       "187  The user is asking for hiking information about Mt. Takao (é«˜å°¾å±±). T...   \n",
       "\n",
       "                                 metric  \n",
       "0    âœ”ï¸ [Prediction(\\n    score=1.0\\n)]  \n",
       "1    âœ”ï¸ [Prediction(\\n    score=1.0\\n)]  \n",
       "2    âœ”ï¸ [Prediction(\\n    score=0.0\\n)]  \n",
       "3    âœ”ï¸ [Prediction(\\n    score=1.0\\n)]  \n",
       "4    âœ”ï¸ [Prediction(\\n    score=1.0\\n)]  \n",
       "..                                  ...  \n",
       "183  âœ”ï¸ [Prediction(\\n    score=1.0\\n)]  \n",
       "184  âœ”ï¸ [Prediction(\\n    score=1.0\\n)]  \n",
       "185  âœ”ï¸ [Prediction(\\n    score=1.0\\n)]  \n",
       "186  âœ”ï¸ [Prediction(\\n    score=1.0\\n)]  \n",
       "187  âœ”ï¸ [Prediction(\\n    score=1.0\\n)]  \n",
       "\n",
       "[188 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = evaluate(optimized_program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "820f6589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>answer</th>\n",
       "      <th>predicted_agent</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>score</th>\n",
       "      <th>is_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>çœ ã‚Œãªã„å¤œã«è´ãéŸ³æ¥½ã‚’æ¢ã—ã¦ã‚‹</td>\n",
       "      <td>transfer_to_music_and_video</td>\n",
       "      <td>transfer_to_music_and_video</td>\n",
       "      <td>The user is looking for music to listen to on sleepless nights. Th...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>å¯¾ç§°æ€§ã®ç¾ã—ã„ç”»åƒã‚’è¦‹ãŸã„ã§ã™ã€‚</td>\n",
       "      <td>transfer_to_image_agent</td>\n",
       "      <td>transfer_to_image_agent</td>\n",
       "      <td>The user is asking to see beautiful images with symmetry (\"å¯¾ç§°æ€§ã®ç¾ã—ã„...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ã®é…é€çŠ¶æ³</td>\n",
       "      <td>transfer_to_web_search</td>\n",
       "      <td>transfer_to_shopping_agent</td>\n",
       "      <td>The user is asking about the delivery status of an online shopping...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ä»Šæ—¥ã®æœè£…ã®ãŠã™ã™ã‚ã¯ï¼Ÿ</td>\n",
       "      <td>transfer_to_web_search</td>\n",
       "      <td>transfer_to_web_search</td>\n",
       "      <td>The user is asking for clothing recommendations for today, which i...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ä»Šæ—¥ç™ºç”Ÿã—ãŸåœ°éœ‡æƒ…å ±ã‚’æ•™ãˆã¦</td>\n",
       "      <td>transfer_to_web_search</td>\n",
       "      <td>transfer_to_web_search</td>\n",
       "      <td>The user is requesting information about earthquakes that occurred...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            message                       answer              predicted_agent  \\\n",
       "0   çœ ã‚Œãªã„å¤œã«è´ãéŸ³æ¥½ã‚’æ¢ã—ã¦ã‚‹  transfer_to_music_and_video  transfer_to_music_and_video   \n",
       "1  å¯¾ç§°æ€§ã®ç¾ã—ã„ç”»åƒã‚’è¦‹ãŸã„ã§ã™ã€‚      transfer_to_image_agent      transfer_to_image_agent   \n",
       "2  ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ã®é…é€çŠ¶æ³       transfer_to_web_search   transfer_to_shopping_agent   \n",
       "3      ä»Šæ—¥ã®æœè£…ã®ãŠã™ã™ã‚ã¯ï¼Ÿ       transfer_to_web_search       transfer_to_web_search   \n",
       "4    ä»Šæ—¥ç™ºç”Ÿã—ãŸåœ°éœ‡æƒ…å ±ã‚’æ•™ãˆã¦       transfer_to_web_search       transfer_to_web_search   \n",
       "\n",
       "                                                               reasoning  \\\n",
       "0  The user is looking for music to listen to on sleepless nights. Th...   \n",
       "1  The user is asking to see beautiful images with symmetry (\"å¯¾ç§°æ€§ã®ç¾ã—ã„...   \n",
       "2  The user is asking about the delivery status of an online shopping...   \n",
       "3  The user is asking for clothing recommendations for today, which i...   \n",
       "4  The user is requesting information about earthquakes that occurred...   \n",
       "\n",
       "   score  is_correct  \n",
       "0    1.0        True  \n",
       "1    1.0        True  \n",
       "2    0.0       False  \n",
       "3    1.0        True  \n",
       "4    1.0        True  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = gepa_results_to_df(result.results)\n",
    "df_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9d681ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_agent\n",
       "transfer_to_web_search         78\n",
       "transfer_to_music_and_video    54\n",
       "transfer_to_shopping_agent     25\n",
       "transfer_to_travel_agent       16\n",
       "transfer_to_image_agent        15\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result['predicted_agent'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c57db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_correct\n",
       "True     185\n",
       "False      3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result['is_correct'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_gepa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
